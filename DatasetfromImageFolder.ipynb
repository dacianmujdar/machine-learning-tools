{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a machine learning dataset from image folder\n",
    "\n",
    "Creates an image dataset suitable for machine learning. \n",
    "It expects as input a directory containing the images grouped in subfolders \n",
    "\n",
    "data/ <br>\n",
    "&nbsp;&nbsp;&nbsp;category1/ <br>\n",
    "&nbsp;&nbsp;&nbsp;category2/ <br>\n",
    "&nbsp;&nbsp;&nbsp;category3/ <br>\n",
    "&nbsp;&nbsp;&nbsp;.......... <br>\n",
    "\n",
    "The script will extract the filenames and the categories in the directory and it will assign the label to each image. \n",
    "After shuffling the data, it will split it into train and test set in the proportion set by the parameter TRAIN_TEST_SPLIT\n",
    "\n",
    "The result will be 4 numpy arrays <br>\n",
    "&nbsp;&nbsp;&nbsp;train_files <br>\n",
    "&nbsp;&nbsp;&nbsp;train_labels <br>\n",
    "&nbsp;&nbsp;&nbsp;test_files <br>\n",
    "&nbsp;&nbsp;&nbsp;test_labels <br>\n",
    "Which will be stored in a specified file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np \n",
    "from random import shuffle\n",
    "import glob\n",
    "\n",
    "directory = 'data/'\n",
    "data_file = 'data.npz'\n",
    "\n",
    "\n",
    "# The percent of data that will be included in the test set\n",
    "TRAIN_TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels from the directory \n",
    "labels = [x[1] for x in os.walk(directory)][0]\n",
    "\n",
    "labels = sorted(labels)\n",
    "\n",
    "labels = labels[1:]\n",
    "\n",
    "num_labels = len(labels)\n",
    "\n",
    "# build dictionary for indexes\n",
    "label_indexes = {labels[i]: i for i in range(0, len(labels))}\n",
    "\n",
    "label_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/u/u_292.jpg 21\n",
      "data/b/b_108.jpg 2\n",
      "data/u/u_672.jpg 21\n",
      "data/i/i_670.jpg 9\n",
      "data/r/r_733.jpg 18\n",
      "data/q/q_692.jpg 17\n",
      "data/l/l_612.jpg 12\n",
      "data/u/u_417.jpg 21\n",
      "data/x/x_282.jpg 24\n",
      "data/a/a_338.jpg 1\n"
     ]
    }
   ],
   "source": [
    "# get the filepaths \n",
    "data_files = glob.glob(directory + '**/*.jpg', recursive=True)\n",
    "\n",
    "# shuffle the data \n",
    "shuffle(data_files)\n",
    "\n",
    "num_data_files = len(data_files)\n",
    "\n",
    "data_labels = []\n",
    "# build the labels \n",
    "for file in data_files:\n",
    "    label = file.split('/')[1]\n",
    "    data_labels.append(label_indexes[label])\n",
    "\n",
    "# just a check to see if everything is ok\n",
    "for i in range(10):\n",
    "    print(data_files[i], data_labels[i])\n",
    "\n",
    "assert num_data_files == len(data_labels)    \n",
    "\n",
    "# convert the labels to one hot\n",
    "data_labels = np.array(data_labels)\n",
    "data_labels_one_hot = tf.keras.utils.to_categorical(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN/TEST split \n",
    "nr_test_data = int(num_data_files * TRAIN_TEST_SPLIT)\n",
    "\n",
    "train_data_files = data_files[nr_test_data:]\n",
    "test_data_files = data_files[:nr_test_data]\n",
    "\n",
    "train_labels = data_labels_one_hot[nr_test_data:]\n",
    "test_labels = data_labels_one_hot[:nr_test_data]\n",
    "\n",
    "assert len(train_labels) + len(test_labels) == num_data_files\n",
    "assert len(test_data_files) + len(train_data_files) == num_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(data_file, \n",
    "         train_data_files=train_data_files, \n",
    "         test_data_files=test_data_files, \n",
    "         train_labels=train_labels, \n",
    "         test_labels=test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}